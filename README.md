# Realtime Network for Acoustic Monitoring

## Image Classification
1. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications [MobileNets](https://arxiv.org/abs/1704.04861)
2. MobileNetV2: Inverted Residuals and Linear Bottlenecks [MobileNetV2](https://arxiv.org/pdf/1801.04381.pdf) [MobileNetV2-pytorch](https://github.com/Randl/MobileNetV2-pytorch)
3. Efficient Net: Rethinking Model Scaling for Convolutional Neural Networks. [ICML 2019](https://arxiv.org/pdf/1905.11946.pdf) [tfcode](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet) [unofficial pytorch version](https://github.com/zsef123/EfficientNets-PyTorch)
4. EfficientNetV2: Smaller Models and Faster Training [arxiv2021](https://arxiv.org/abs/2104.00298) [EfficientNetV2](https://github.com/google/automl/efficientnetv2)
5. ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices [ShuffleNet](https://arxiv.org/abs/1707.01083)
6. ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design [ShuffleNet V2]( https://arxiv.org/abs/1807.11164)   [Shufflenet-v2-Pytorch](https://github.com/ericsun99/Shufflenet-v2-Pytorch)
7. ShuffleNetV2+：[paper unrelease]() [code](https://github.com/megvii-model/ShuffleNet-Series/tree/master/ShuffleNetV2%2B)  *ShuffleNet Series by Megvii Research*
8. CondenseNet: An Efficient DenseNet using Learned Group Convolutions [CondenseNet](https://arxiv.org/abs/1711.09224)
9. CondenseNet V2: Sparse Feature Reactivation for Deep Networks [CondenseNetV2](https://github.com/jianghaojun/CondenseNetV2)
10. MicroNet: Towards Image Recognition with Extremely Low FLOPs [arxiv2020](https://arxiv.org/abs/2011.12289v1) *UC San Diego && Microsoft*

## Object Detection
1. EfficientDet: Scalable and Efficient Object Detection [arxiv2019](https://arxiv.org/pdf/1911.09070.pdf)  [unofficial-EfficientDet.Pytorch](https://github.com/toandaominh1997/EfficientDet.Pytorch) *Google Research, Brain Team*
2. YOLOv4: Optimal Speed and Accuracy of Object Detection [arxiv2020](https://arxiv.org/pdf/2004.10934.pdf) [OfficialRepo](https://github.com/AlexeyAB/darknet) [Minimal PyTorch](https://github.com/Tianxiaomo/pytorch-YOLOv4) [Tensorflow 2.0Repo](https://github.com/hunglc007/tensorflow-yolov4-tflite) [KerasRepo](https://github.com/Ma-Dan/keras-yolo4)
3. YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection [arxiv2019](https://arxiv.org/abs/1910.01271)

## Neural Architecture Search

1. PC-DARTS: Partial Channel Connections for Memory-Efficient Differentiable Architecture Search [arxiv2019](https://arxiv.org/pdf/1907.05737.pdf) [code](https://github.com/yuhuixu1993/PC-DARTS) *Shanghai Jiao Tong University&&Huawei*
2. Densely Connected Search Space for More Flexible Neural Architecture Search [arxiv2019](https://arxiv.org/pdf/1906.09607.pdf) [code](https://github.com/JaminFong/DenseNAS) *Huazhong University of Science and Technology &&Horizon Robotics*
3. FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search [arxiv2019](https://arxiv.org/pdf/1907.01845.pdf) [code](https://github.com/fairnas/FairNAS) *Xiaomi AI Lab*
4. XferNAS: Transfer Neural Architecture Search [arxiv2019](https://arxiv.org/pdf/1907.08307.pdf) *IBM Research*
5. AutoML: A Survey of the State-of-the-Art [arxiv2019](https://arxiv.org/pdf/1908.00709.pdf)  *Hong Kong Baptist University*
6. MoGA: Searching Beyond MobileNetV3 [arxiv2019](https://arxiv.org/abs/1908.01314) [code](https://github.com/xiaomi-automl/MoGA) *Xiaomi AI Lab*
7. ScarletNAS: Bridging the Gap Between Scalability and Fairness in Neural Architecture Search [arxiv2019](https://arxiv.org/pdf/1908.06022.pdf) [code](https://github.com/xiaomi-automl/SCARLET-NAS)  *Xiaomi AI Lab && IoT*
8. BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search [arxiv](https://arxiv.org/pdf/1910.11858.pdf) [code](https://github.com/naszilla/bananas) [blog](https://medium.com/reality-engines/bananas-a-new-method-for-neural-architecture-search-192d21959c0c)
9. Fast and Practical Neural Architecture Search [iccv2019](http://jiaya.me/papers/fpnas_iccv19.pdf) *CUHK && YouTu Lab, Tencent*
10. Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search [arxiv2019](https://arxiv.org/pdf/1911.12126.pdf) [FairDARTS](https://github.com/xiaomi-automl/FairDARTS) *Xiaomi AI Lab &&Minzu University of China*
11. SGAS: Sequential Greedy Architecture Search [arxiv2019](https://arxiv.org/pdf/1912.00195.pdf) [project]() *KAUST &&  Intel Labs*
12. Blockwisely Supervised Neural Architecture Search with Knowledge Distillation  [arxiv2019](https://arxiv.org/abs/1911.13053) [DNA](https://github.com/jiefengpeng/DNA) *DarkMatter AI Research && Monash University &&Sun Yat-sen University*
13. EDAS: Efficient and Differentiable Architecture Search [arxiv2019](https://128.84.21.199/pdf/1912.01237.pdf) *KAIST* 
14. Efficient Differentiable Neural Architecture Search with Meta Kernels [arxiv2019](https://arxiv.org/pdf/1912.04749.pdf) *HUST &&YITU &&NUS*
15. AtomNAS: Fine-Grained End-to-End Neural Architecture Search [ICIR2020](https://openreview.net/pdf?id=BylQSxHFwr) [AutoNAS](https://github.com/meijieru/AtomNAS) *Johns Hopkins University && ByteDance AI Lab*
16. EcoNAS: Finding Proxies for Economical Neural Architecture Search [arxiv2020](https://arxiv.org/pdf/2001.01233.pdf) *The University of Sydney &&Nanyang Technological University&&SenseTime Research*
17. MixPath: A Unified Approach for One-shot Neural Architecture Search [arxiv2020](https://arxiv.org/pdf/2001.05887.pdf) [MixPath](https://github.com/xiaomi-automl/MixPath) *Xiaomi AI Lab &&UCAS*

## Training


1.  [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)	(Apr 25, 2019)
2.  [Improving deep learning models with bag of tricks](https://github.com/kmkolasinski/deep-learning-notes/tree/master/seminars/2018-12-Improving-DL-with-tricks) (Dec 13,2018)
3.  [A Bag of Tricks for Image Classification](https://towardsdatascience.com/a-big-of-tricks-for-image-classification-fec41eb28e01) (Dec 17, 2018)
4.  Bag of Tricks for Image Classification with Convolutional Neural Networks [cvpr2019](https://arxiv.org/abs/1812.01187) [code](https://github.com/dmlc/gluon-cv)
5.  Bag of Freebies for Training Object Detection Neural Networks [arxiv2019](https://arxiv.org/abs/1902.04103) [code](https://github.com/dmlc/gluon-cv)
6.  Bag of Tricks for Image Classification by Arthur Kuzin [2020slide](https://docs.google.com/presentation/d/1TcHW6aH0QrcLG_SazEjGx5RCsNjF2SQ9gzIR4RKOsRU/edit#slide=id.p)
7.  carrier-of-tricks-for-classification-pytorch [2020code](https://github.com/hoya012/carrier-of-tricks-for-classification-pytorch)
8.  [Faster Deep Learning Training with PyTorch – a 2021 Guide](https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/#17-use-input-and-batch-normalization)
